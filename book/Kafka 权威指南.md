# Kafka 权威指南

## 初识 Kafka

## 安装 Kafka

* （2.2）执行范例中消费命令 kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning 报错为 [zookeeper is not a recognized option when executing kafka-console-consumer.sh](https://stackoverflow.com/a/53429129), 寻找到问题是 kafka 新版本(>0.9) 将消费命令更新为 kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

## Kafka 生产者

* log.segment.bytes: 当日志片段大小达到此参数指定的上限（默认 1GB）时，当前日志就会被关闭，一个新的日志片段被打开。如果一个日志片段被关闭，就开始等待过期。这个参数的值越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率。如果主题的消息量不大，那么如何调整这个参数的大小就变得尤为重要。例如，如果一个主题每天只接收 100MB 的消息， 而 log.segment.bytes 使用默认设置， 那么需要 10 天时间才能填满一个日志片段。因为在日志片段被关闭之前消息是不会过期的，所以如果 log.retention.ms 被设为 604800000（也就是 1 周），那么日志片段最多需要 17 天才会过期。 这是因为关闭日志片段需要 10 天的时间，而根据配置的过期时间，还需要再保留 7 天时间（要等到日志片段里的最后一个消息过期才能被删除）。使用时间戳获取偏移量：日志片段的大小会影响使用时间戳获取偏移量。在使用时间戳获取日志偏移量时，Kafka 会检查分区里最后修改时间大于指定时间戳的日志片段（已经被关闭的），该日志片段的前一个文件的最后修改时间小于指定时间戳。然后，Kafka 返回该日志片段（也就是文件名）开头的偏移量。对于使用时间戳获取偏移量的操作来说，日志片段越小，结果越准确。  —— 2.3.2
* log.segment.ms：另一个可以控制日志片段关闭时间的参数是 log.segment.ms，它指定了多长时间之后日志片段会被关闭。就像 log.retention.bytes 和 log.retention.ms 这两个参数一样，log.segment.bytes 和 log.retention.ms 这两个参数之间也不存在互斥问题。日志片段会在大小或时间达到上限时被关闭，就看哪个条件先得到满足。默认情况下，log.segment.ms 没有设定值，所以只根据大小来关闭日志片段。基于时间的日志片段对磁盘性能的影响：在使用基于时间的日志片段时，要着重考虑并行关闭多个日志片段对磁盘性能的影响。如果多个分区的日志片段永远不能达到大小的上限，就会发生这种情况，因为 broker 在启动之后就开始计算日志片段的过期时间，对于那些数据量小的分区来说，日志片段的关闭操作总是同时发生。    —— 2.3.2
* 顺序保证：Kafka可以保证同一个分区里的消息是有序的。也就是说，如果生产者按照一定的顺序发送消息，broker就会按照这个顺序把它们写入分区，消费者也会按照同样的顺序读取它们。在某些情况下，顺序是非常重要的。例如，往一个账户存入100元再取出来，这个与先取钱再存钱是截然不同的！不过，有些场景对顺序不是很敏感。如果把retries设为非零整数，同时把max.in.flight.requests.per.connection设为比1大的数，那么，如果第一个批次消息写入失败，而第二个批次写入成功，broker会重试写入第一个批次。如果此时第一个批次也写入成功，那么两个批次的顺序就反过来了。一般来说，如果某些场景要求消息是有序的，那么消息是否写入成功也是很关键的，所以不建议把retries设为0。可以把max.in.flight.requests.per.connection设为1，这样在生产者尝试发送第一批消息时，就不会有其他的消息发送给broker。不过这样会严重影响生产者的吞吐量，所以只有在对消息的顺序有严格要求的情况下才能这么做。     —— 3.4
* schema.registry.url 的问题，参考 [How to set schema.registry.URL?](https://stackoverflow.com/a/51904064), 先从这里 [Confluent Platform](https://www.confluent.io/download/) 下载一个 Self managed event streaming platform, 填写 email，选择手动部署，选择 tar，最终下载一个类似名为 confluent-5.5.1-2.12.tar.gz 的文件，然后解压，进入文件夹 etc/schema-registry/schema-registry.properties 设定 listeners=http://localhost:8081, 然后返回文件夹顶级目录运行 bin/schema-registry-start etc/schema-registry/schema-registry.properties 即可。
* 分区：如果键值为 null，并且使用了默认的分区器，那么记录将被随机地发送到主题内各个可用的分区上。分区器使用轮询（Round Robin）算法将消息均衡地分布到各个分区上。如果键不为空，并且使用了默认的分区器，那么 Kafka 会对键进行散列（使用Kafka自己的散列算法，即使升级 Java 版本，散列值也不会发生变化），然后根据散列值把消息映射到特定的分区上。       —— 3.6

## Kafka 消费者

* 分配分区是怎样的一个过程：当消费者要加入群组时，它会向群组协调器发送一个 JoinGroup 请求。第一个加入群组的消费者将成为“群主”。群主从协调器那里获得群组的成员列表（列表中包含了所有最近发送过心跳的消费者，它们被认为是活跃的），并负责给每一个消费者分配分区。它使用一个实现了 PartitionAssignor 接口的类来决定哪些分区应该被分配给哪个消费者。       —— 4.1.2

## 深入 Kafka

* Kafka 如何进行复制; Kafka 如何处理来自生产者和消费者的请求; Kafka 的存储细节，比如文件格式和索引。      —— 5
* acks 这个配置参数——该参数指定了要多少个 broker 确认才可以认为一个消息写入是成功的。不同的配置对写入成功的界定是不一样的，如果 acks=1，那么只要首领收到消息就认为写入成功；如果 acks=all，那么需要所有同步副本收到消息才算写入成功；如果 acks=0，那么生产者在把消息发出去之后，完全不需要等待 broker 的相应。     —— 5.4.1
* 如果请求的偏移量存在，broker 将按照客户端指定的数量上限从分区里读取消息，再把消息返回给客户端。Kafka 使用零复制技术向客户端发送消息——也就是说，Kafka 直接把消息从文件（或者更准确地说是 Linux 文件系统缓存）里发送到网络通道，而不需要经过任何中间缓冲区。这是 Kafka 与其他大部分数据库系统不一样的地方，其他数据库在将数据发送给客户端之前会先把它们保存在本地缓存里。这项技术避免了字节复制，也不需要管理内存缓冲区，从而获得更好的性能。       —— 5.4.2
* 注意磁盘空间：要注意，在为 broker 分配分区时并没有考虑可用空间和工作负载问题，但在将分区分配到磁盘上时会考虑分区数量，不过不考虑分区大小。也就是说，如果有些 broker 的磁盘空间比其他 broker 要大（有可能是因为集群同时使用了旧服务器和新服务器），有些分区格外大。或者同一个 broker 上有大小不同的磁盘，那么在分配分区时要格外小心。在后面的章节中，我们会讨论 Kafka 管理员该如何解决这种 broker 负载不均衡的问题。     —— 5.5.1

## 可靠的数据传递

* 了解系统的保证机制对于构建可靠的应用程序来说至关重要，这也是能够在不同条件下解释系统行为的前提，那么 Kafka 可以在哪些方面做出保证呢？ Kafka 可以保证分区消息的顺序；只有当消息被写入到分区的所有同步副本时（但不一定要写入磁盘），它才被认为是"已提交的"；只要还有一个副本是活跃的，那么已经提交的信息就不会丢失；消费者只能读取已经提交的消息。  —— 6.1
* 非同步副本：如果一个或多个副本在同步和非同步之间快速切换，说明集群内部出现了问题，通常是 Java 不恰当的垃圾回收配置导致的。不恰当的垃圾回收配置会造成几秒钟的停顿，从而让 broker 与 zookeeper 之间断开连接，最后变成不同步的，进而发生状态切换。  —— 6.2
* 不完全的首领选举：如果把 unclean.leader.election.enable 设为 true，就是允许不同步的副本成为首领（也就是“不完全的选举”），那么我们将面临丢失消息的风险。如果把这个参数设为 false，就要等待原先的首领重新上线，从而降低了可用性。我们经常看到一些对数据质量和数据一致性要求较高的系统会禁用这种不完全的首领选举（把这个参数设为 false）。银行系统是这方面最好的例子，大部分银行系统宁愿选择在几分钟甚至几个小时内不处理信用卡支付事务，也不会冒险处理错误的消息。不过在对可用性要求较高的系统里，比如实时点击流分析系统，一般会启用不完全的首领选举。   —— 6.3.2
* 额外的错误处理：使用生产者内置的重试机制可以在不造成消息丢失的情况下轻松处理大部分错误，不过对于开发人员来说，仍然需要处理其他类型的错误，包括：不可重试的 broker 错误，例如消息大小错误、认证错误等；在消息发送之前发生的错误，例如序列化错误；在生产者达到重试次数上限时或者在消费占用的内存达到上限时发生的错误。    —— 6.4.3
* 已提交消息与已提交偏移量：要注意，此处的已提交消息与之前讨论过的已提交消息是不一样的，它是指已经被写入所有同步副本并且对消费者可见的消息，而已提交偏移量是指消费者发送给 Kafka 的偏移量，用于确认它已经收到并处理好的消息位置。   —— 6.5
* exactly-once：有些应用程序不仅仅需要“至少一次”（at-least-once）语义（意味着没有数据丢失），还需要“仅一次”（exactly-once）语义。尽管 Kafka 现在还不能完全支持仅一次语义，消费者还是有一些办法可以保证 Kafka 里的每个消息只被写到外部系统一次（但不会处理向 Kafka 写入数据时可能出现的重复数据）。实现仅一次处理最简单且最常用的办法是把结果写到一个支持唯一键的系统里，比如键值存储引擎、关系型数据库、ElasticSearch 或其他数据存储引擎。在这种情况下，要么消息本身包含一个唯一键（通常都是这样），要么使用主题、分区和偏移量的组合来创建唯一键——它们的组合可以唯一标识一个 Kafka 记录。如果你把消息和一个唯一键写入系统，然后碰巧又读到一个相同的消息，只要把原先的键值覆盖掉即可。数据存储引擎会覆盖已经存在的键值对，就像没有出现过重复数据一样。这个模式被叫作幂等性写入，它是一种很常见也很有用的模式。如果写入消息的系统支持事务，那么就可以使用另一种方法。最简单的是使用关系型数据库，不过 HDFS 里有一些被重新定义过的原子操作也经常用来达到相同的目的。我们把消息和偏移量放在同一个事务里，这样它们就能保持同步。在消费者启动时，它会获取最近处理过的消息偏移量，然后调用seek()方法从该偏移量位置继续读取数据。我们在第4章已经介绍了一个相关的例子。   —— 6.5.2
* 可靠性：正如我们在本章开头所说的，可靠性并不只是 Kafka 单方面的事情。我们应该从整个系统层面来考虑可靠性问题，包括应用程序的架构、生产者和消费者 API 的使用方式、生产者呵呵消费者的配置、主题的配置以及 broker 的配置。系统的可靠性需要在许多方面作出权衡，比如复杂性、性能、可用性和磁盘空间的使用。掌握 Kafka 的各种配置和常用模式，对使用场景的需求做到心中有数，你就可以在应用程序和 Kafka 的可靠性程度以及各种权衡之间作出更好的选择。    —— 6.7

## 构建数据管道

* Kafka 为数据管道带来的主要价值在于，它可以作为数据管道各个数据段之间的大型缓冲区，有效地解耦管道数据的生产者和消费者。Kafka 的解耦能力以及在安全和效率方面的可靠性，使它成为构建数据管道的最佳选择。  —— 7

## 跨集群数据镜像

* 要注意，在 Linux 上进行网络调优包含了太多复杂的内容。为了了解更多参数和细节，建议阅读相关的网络调优指南。例如，由 Sandra K.Johnson 等人合著的 Performance tuning for Linux Servers.  —— 8.3.3
* linger.ms和batch.size：如果在进行监控时发现生产者总是发送未填满的批次（比如，度量指标 batch-size-avg 和 batch-size-max 的值总是比 batch.size 低），那么就可以通过增加一些延迟来提升吞吐量。通过增加 latency.ms 可以让生产者在发送批次之前等待几毫秒，让批次填充更多的数据。如果发送的数据都是满批次的，同时还有空余的内存，那么可以配置更大的 batch.size，以便发送更大的批次。

## 管理 Kafka

* 减少分区数量：我们无法减少主题的分区数量。因为如果删除了分区，分区里的数据也一并被删除，导致数据不一致。我们也无法将这些数据分配给其他分区，因为这样做很难，而且会出现消息乱序。所以，如果一定要减少分区数量，只能删除整个主题，然后重新创建它。
* 运行一个 Kafka 集群需要付出很大的努力，为了让 Kafka 保持巅峰状态，需要做大量的配置和维护。我们在这一章里介绍了 Kafka 的很多日常操作，比如经常会用到的主题管理和客户端配置；也介绍了一些用于诊断问题的复杂操作，比如检查日志片段；最后还介绍了一些不安全的操作，这些操作在特殊的情况下可以帮你解决问题。通过执行这些操作，你就可以更好地管理 Kafka 集群。  —— 9.8

## 监控 Kafka

* Kafka 应用程序包含了大量的度量指标，以至于很多人搞不清楚哪些是重要的，哪些可以置之不理。它们所涉及的范围，从简单的流量速率度量指标到各种请求类型的时间度量指标，既有主题级别的，也有分区级别的。这些度量指标为 broker 的每一种行为提供了详细的信息，不过它们也成为了 Kafka 系统监控者的“噩梦”。 这一章将详细介绍一些常用的关键性度量指标，以及如何根据这些指标采取相应的行动，也会介绍一些用于调试问题的度量指标。不过，这不是一个完整的度量指标清单。度量指标清单会经常发生变化，而且很多度量指标只对有经验的Kafka开发人员有参考价值。  —— 10
* 如果说 broker 只有一个可监控的度量指标，那么它一定是指非同步分区的数量。该度量指明了作为首领的 broker 有多少个分区处于非同步状态。这个度量可以反映Kafka的很多内部问题，从 broker 的崩溃到资源的过度消耗。因为这个度量指标可以说明很多问题，所以当它的值大于零时，就应该想办法采取相应的行动。如果非同步分区的数量是波动的，或者虽然数量稳定但并没有 broker 离线，说明集群出现了性能问题。这类问题繁复多样，难以诊断，不过可以通过一些步骤来缩小问题的范围。第一步，先确认问题是与单个 broker 有关还是与整个集群有关。不过有时候这个也难有定论。如果非同步分区属于单个 broker，那么这个 broker 就是问题的根源，表象是其他 broker 无法从它那里复制消息。如果多个 broker 都出现了非同步分区，那么有可能是集群的问题，也有可能是单个 broker 的问题。这时候有可能是因为一个 broker 无法从其他 broker 那里复制数据。为了找出这个 broker，可以列出集群的所有非同步分区，并检查它们的共性。  —— 10.2.1
* 集群问题一般分为以下两类：不均衡的负载；资源过度消耗。分区或首领的不均衡问题虽然解决起来有点复杂，但问题的定位是很容易的。为了诊断这个问题，需要用到 broker 的以下度量指标：分区的数量；首领分区的数量；主题流入字节速率；主题流入消息速率。  —— 10.2.1
* Kafka 集群的另一个性能问题是容量瓶颈。有很多潜在的瓶颈会拖慢整个系统：CPU、磁盘 IO 和网络吞吐量是其中最为常见的。磁盘的使用并不在其列，因为当磁盘被填满时，broker 会在进行适当的操作之后直接崩溃。为了诊断容量问题，可以对如下一些操作系统级别的度量指标进行监控。CPU 使用；网络输入吞吐量；网络输出吞吐量；磁盘平均等待时间；磁盘使用百分比。  —— 10.2.1
* 流出速率也包括副本流量，也就是说，如果所有主题都设置了复制系数 2， 那么在没有消费者客户端的情况下，流出速率与流入速率是一样的。如果有一个消费者客户端从集群读取所有的消息，那么流出速率会是流入速率的 2 倍。如果不知道这一点，光是看着这些指标就会感到很疑惑。  —— 10.2.2
* 最后一个值得推荐的指标是 record-queue-time-avg，它表示消息在发送给 Kafka 之前在生产者客户端等待的平均毫秒数。应用程序在使用生产者客户端发送消息（调用 send 方法）之后，生产者会一直等待，直到以下任一情况发生：生产者客户端有足够多的消息来填充批次（根据 max.partition.bytes 的配置）。根据距离上一次发送批次已经有足够长的时间（根据 linger.ms 的配置）。这两种情况都会促使生产者客户端关闭当前批次，然后把它发送给 broker。 对于繁忙的主题来说，一般会发生第一种情况，而对于比较慢的主题来说，一般会发生第二种情况。record-queue-time-avg 用于度量生产消息所使用的时间，因此，可以通过调优上述两个参数来满足应用程序的延迟需求。  —— 10.3.1

## 流式处理









