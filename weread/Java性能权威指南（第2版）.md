## Java性能权威指南（第2版）

 **斯科特·奥克斯**


### 前言

* 这是典型的应用程序发展历程（JVM本身也是应用程序）：在项目初期，很容易找到架构上的改进点（或代码缺陷），改进后会带来巨大的性能提升。在成熟的应用程序中，很少能找到这样的性能改进点。

* 平台的进化带来了一个值得注意的性能关注点：在两个程序之间用JSON交换信息，毫无疑问比使用高度优化的专有协议更加简洁和高效。为开发人员节省时间确实可以提升生产力，但是确保在生产力提升的同时性能也提升（至少打平）才是真正的目标。


### 第1章 导论

* 这些知识分为两大部分。第一部分关于Java虚拟机（Java Virtual Machine，JVM）的性能优化，即如何通过JVM的配置方式影响程序的性能。使用其他语言的资深开发人员可能认为JVM优化有点令人厌烦，但实际上，JVM优化类似于C++程序员在编译阶段测试和挑选编译器参数，或者PHP程序员在php.ini文件中设置合适的变量。
第二部分关于理解Java平台的特性如何影响性能。注意，这里使用了平台这个词：有些平台特性（比如线程和同步）是Java语言的一部分，而有些平台特性（比如字符串处理）是Java标准API的一部分。尽管Java语言和Java API有着显著的区别，但在本书中，两者会被同等对待。这两方面在本书中都会讲到。


### 1.2 平台和约定

* 除了少数例外，JVM接收两种标志：布尔标志和附带参数的标志。
布尔标志使用的语法是：-XX:+FlagName表示开启，-XX:-FlagName表示关闭。
附带参数的标志使用的语法是：-XX:FlagName=something，表示设置FlagName的值为something。其中，something指表示任意值的符号。例如，-XX:NewRatio=N表示NewRatio标志可以设成任意值N（N的含义将是讨论的重点）。

* 所以，如果4核机器开启超线程，似乎就可以同时执行8个线程的指令（尽管从技术上讲，每个CPU周期只能执行4条指令）。这对于操作系统，也就是Java和其他应用程序来说，机器可以表现得像拥有8个CPU一样。但从性能的角度来讲，这些CPU并不等价。如果运行一个CPU密集型任务，它只会使用1个核心；运行两个CPU密集型任务才会用到第2个核心；以此类推，直到第4个核心。也就是说，独立运行4个CPU密集型任务可以得到4倍的吞吐量。
如果添加第5个任务，它只能在任何其他任务暂停时运行。该任务的运行时间平均占总时间的20%到40%。额外的任务都面临这一挑战。因此，添加第5个任务只能提高约30%的性能。结论就是，使用超线程技术得到的8个CPU能使机器性能达到单核的五六倍。
你将在后文的几个章节中看到这个例子。垃圾回收很大程度上是CPU密集型任务，所以第5章介绍了超线程如何影响垃圾回收算法的并行化。第9章大致讨论了如何充分利用Java的多线程能力，你也会看到扩展超线程核心的例子。

* 默认情况下，Docker容器可以自由使用机器上的所有资源，包括所有可用的CPU和内存。如果使用Docker仅仅是为了在机器上快速部署单一应用程序，并且机器只运行这一个Docker容器，那没问题。但其实经常需要在机器上运行多个Docker容器，还要限制每个容器的资源。鉴于我们的4核机器有16 GB内存，我们可能希望运行两个Docker容器，每个可获取2个核心和8 GB内存。

* 在Java 8的早期版本中，JVM无法得知任何容器的限制：当检测机器剩余内存以确定默认的堆大小时，它会检测机器的所有内存，但我们更希望看到的是允许Docker容器使用的内存。同样，检查有多少CPU可以用来优化垃圾回收器时，它会检查机器上所有的CPU，而不是只检查分配给Docker容器的CPU。结果是，JVM运行状态不理想：启用的线程过多，设置的堆过大。线程过多会导致性能下降，但真正的问题出在内存上：堆的最大大小比分配给Docker容器的内存还大，当堆增大到这个大小时，Docker容器（以及JVM）会停止运行。


### 1.3 全面的性能

* 归根结底，程序的性能取决于程序怎么写。如果使用循环遍历数组中的所有元素，那么JVM可以优化数组的边界检查方式，让循环运行得更快，还可以展开循环操作以提供额外的加速。如果使用循环是为了查找某个特定的元素，那么世界上还没有可行的优化方式，能让基于数组的代码和使用哈希映射（hash map）一样快。
好的算法对于提升性能是至关重要的。

* 我们最终会输掉这场战争
一个反常（令人沮丧）的地方是，每个应用程序的性能都会随着时间下降，准确地说是随着应用程序新版本的发布而下降。这种性能差异常常被忽略，因为硬件的改进可以保证新应用程序的运行速度。

* 高德纳被认为是最早创造过早优化这个词的人。开发人员经常使用这个词来宣称，代码的性能重要不重要，得运行了才知道。也许你从不知道，完整的原话是这么说的：“大部分时间里，比如在97%的时间里，我们不应该对细枝末节进行优化。过早优化是万恶之源。”3

* 如果你在开发不依赖外部资源的独立Java应用程序，那么该应用程序本身的性能几乎是最重要的。一旦外部资源（例如数据库）添加进来，那两者的性能就都很重要了。在分布式环境中，如果有Java REST服务器、负载均衡器、数据库和后端企业信息系统，那么Java服务器的性能可能是最不重要的部分。


* 另外，不要忽视最初的分析。如果数据库是瓶颈（提示：它的确是），对访问数据库的Java应用程序进行优化不会提升整体性能。实际上，这有可能适得其反。一个通用的准则是，给已经过载的系统增加负载，系统的性能会变差。如果在Java应用程序中做了一些更改让它更高效，这也会给过载的数据库增加负载，所以实际上整体性能是下降的。若你就此得出“不应使用某项JVM改进”的结论，那就危险了。


### 2.1 测试真实的应用程序

* 在编写多线程微基准测试时要相当警惕。当多个线程同时执行一小段代码时，发生同步瓶颈（和其他线程问题）的可能性相当大。多线程微基准测试的结果往往会导致需要花费大量时间在优化同步瓶颈上，而不是在解决更紧迫的性能需求上，但同步瓶颈很少出现在实际代码中。

* 到目前为止，我们关注的问题可以通过认真编写微基准测试来解决。代码被纳入到一个更大的系统中后，其他因素也会影响代码运行的最终结果。编译器利用代码的性能分析反馈（profile feedback）决定编译方法时的最佳优化方式。性能分析反馈基于方法被频繁调用、调用栈的深度、参数的实际类型（包括子类）等因素，而这些都是由代码的实际运行环境决定的。


* 尽管有很多缺陷，但微基准测试还是很受欢迎，以至于OpenJDK有一个专门用来开发微基准测试的核心框架：Java微基准测试工具（jmh，Java Microbenchmark Harness）。jmh被JDK开发人员用来构建针对JDK本身的回归测试，同时为开发人员提供了通用的基准测试框架。

* Java的一个性能特点是，代码执行得越多，性能就越好（这个话题会在第4章讲到）。因此，微基准测试必须包含一个预热期，让编译器有机会生成最佳代码。
本章稍后会深入讨论预热期的优点。微基准测试必须有预热期，否则它测量的就是编译性能，而不是代码性能。

* 需要测试完整应用程序的另一个原因是资源分配。在理想的情况下，有足够的时间优化应用程序中的每一行代码。在现实世界里，交付日期迫在眉睫，仅仅优化复杂运行环境的一部分可能不会有立竿见影的效果。

* 在这个例子中，优化数据业务处理所花费的时间并没有被完全浪费。一旦优化了其他的系统瓶颈，性能收益就会显现。准确地说，这是优先级的问题。在没测试整个应用程序的时候，不可能知道优化哪部分的性能会有效果。


* 尽管如此，介基准测试仍不完美。如果使用这种基准测试来比较两台应用程序服务器的性能，那么开发人员很容易误入歧途。


### 2.2 理解吞吐量、批处理时间和响应时间

* 对于静态编译语言，这种测试很简单：编写应用程序，并测量其执行时间。不过，Java世界里的即时编译会带来额外的问题（这个过程在第4章详述）。实际上，这个过程需要几秒到几分钟（甚至更长）的时间将代码充分优化并以最佳性能运行。基于这个（和其他）原因，Java性能研究很注重预热期，其性能的测量通常在相关代码运行足够长的时间、被编译和优化之后。

* 在客户端/服务器测试中，客户端的配置很重要，因为需要保证客户端向服务器发送数据的速度足够快。速度不够快的原因可能是客户端的机器没有足够的CPU周期来运行预期数量的线程，或者客户端在发送新的请求之前需要大量时间来处理请求。在这些情况下，测试实际上是在测量客户端的性能，而不是服务器的性能，这通常不是最初的目标。

* 吞吐量测试常常也会报告请求的平均响应时间。这是一条有趣的信息，只有在所报告的吞吐量相同时，平均响应时间的变化才表示性能有问题。举例来说，以0.5秒的响应时间承载500 OPS的服务器，比以0.3秒的响应时间承载400 OPS的服务器性能好。吞吐量测试几乎都是在适当的预热期之后进行的，因为所需测量的吞吐量并非一成不变。

* 出现异常值的原因有很多，GC引入的暂停时间2会让Java程序更容易出现异常值。在性能测试中，通常关注第90百分位响应时间（或者第95百分位响应时间和第99百分位响应时间。在这里，第90百分位响应时间只是举例说明）。如果你只能测量一个数字，那么最好选择基于百分位响应时间的测试，因为减小这个数字将惠及大多数用户。不过，最好同时测量平均响应时间和至少一个百分位响应时间，这样你就不会错过异常值过大的情况了。

* 在这个例子中，有25个客户端（-c 25）向股票Servlet发送请求（请求股票代码SDO），每个请求的周期时间是1秒（-W 1000）。-r 300/300/60表示这个基准测试有5分钟（300秒）的预热期，接下来是5分钟的测量期和1分钟的减速期。测试结束后，fhb报告了该测试的OPS和各种响应时间。（因为这个例子涉及思考时间，所以响应时间就成了更重要的指标，OPS基本上会是常量。）


### 2.3 理解可变性

* 第三个原则，即理解可变性，是指理解测试结果如何随时间变化。即使处理完全相同的数据集，应用程序每次运行也都会产生不同的结果。这是因为，后台进程会影响应用程序的运行，而且网络在运行时或多或少会出现拥堵。好的基准测试不会每次都使用完全相同的数据集，而是会在测试过程中构建随机行为以模拟真实世界。这就产生了一个问题：当比较两次运行的结果时，差异是由性能造成的，还是由随机变化的测试造成的？这个问题可以通过多次运行测试后取平均值来解决。如果正在测试的代码有修改，那么可以再多运行几次测试，再次对结果取平均值，然后比较这两个平均值。这听起来很简单。不幸的是，事情并没有那么简单，因为很难判断什么时候是真正的性能倒退，什么时候是随机变化。在性能优化这一重要领域，科学引领了方向，艺术也在发挥作用。当比较基准测试结果的平均值时，我们不能绝对地肯定这些平均值的差异是由于真正的性能问题还是随机变化而导致的。最好的办法是假设“平均值是相同的”，然后判断这句话正确的概率。如果这句话错误的概率很高，我们就可以放心地认为平均值的差异是由于真正的性能问题（哪怕我们永远不能100%确定）。

* 像这样因代码改进而进行的测试叫作回归测试（regression testing）。在回归测试中，原本的代码叫作基线（baseline），新的代码叫作样本（specimen）。

* 统计数字及其语义表述正确表述T检验结果的方法是这样的：样本和基线有差异的概率为57%，差异的最佳估值是25%。一般这样表述结果：结果提升25%的置信度是57%。虽然这与前一种说法并不完全相同，也会让统计学家抓狂，但这种说法简洁且易于接受，也不是很离谱。概率分析总会涉及不确定性，准确的表述会让这种不确定性更容易理解。然而，特别是在一个根本问题已被透彻理解的领域，必然会出现语义上的简化。

* 回归测试很重要，但它并不是非黑即白的二元选择。如果不做一些统计分析来理解这些数字的含义，就不能对这一系列数字（或它们的平均值）进行比较判断。但是，概率本身的含义是，即使做了这种分析，也不能得出一个完全确定的答案。性能优化工程师的工作就是查看数据、理解概率，并根据所有可用的数据决定应该先优化哪个问题。


### 2.4 早测试、常测试

* 在测试运行之前，必须通过自动化确保机器处于合适的状态。必须检查并确定没有额外的进程在运行，并且操作系统配置正确。只有当每次的运行环境都一样时，性能测试才是可重复的。自动化必须注意这一点。

* 这些数据可用于分析任何未发现的性能倒退。如果CPU使用率增加了，就需要查阅性能分析信息，看看是什么耗费了更多时间。如果花在GC上的时间增加了，就需要查阅堆性能分析信息，看看是什么占用了更多内存。如果CPU使用率和GC时间都减少了，那么可能是某个地方的资源竞争降低了性能，比如，栈数据有助于找出特定同步瓶颈的原因（见第9章），JFR记录有助于找出应用程序延迟的原因，数据库日志有助于找出导致数据库资源竞争加剧的原因。在查找性能倒退的原因时，需要像侦探一样，可用的数据越多，能推断出的线索就越多。正如第1章所讨论的那样，性能倒退不一定是JVM导致的。测量一切，确保分析结果的正确性。

* 因此，如果不在预期的负载下和预期的硬件上测试，就永远无法完全知道特定生产环境的性能。通过在较小的硬件上运行较小的测试，可以得出近似值以便做出推断。再加上，在现实世界中，复制用于测试的生产环境是相当困难或相当昂贵的。所以，推断只是简单的预测，就算是在最好的情况下，预测也可能是错的。大规模系统不仅仅是各个部分的总和，并且没有什么能替代在目标平台上执行充分的负载测试。


### 2.5 基准测试示例

* 设置代码与低级别测试
后面章节的一些jmh测试会报告特定的操作只相差几纳秒。这些测试并不是在测试单个操作后报告纳秒级时间，而是进行大量操作后报告统计方差内的平均值。jmh会为我们管理这些。
请务必注意：如果每次调用都会执行setup代码，那么jmh很难执行平均调用分析。因为这个（和其他）原因，建议尽量少使用Level.Invocation注解，最好只在测试方法本身耗时较长的情况下使用。

* 至于在实际情况中需要多少次迭代、多少次派生试验、多长的执行时间，才能获取足够的数据让结果这样清晰，并没有硬性规定。如果你比较的两个技术之间差别不大，那么你会需要更多的迭代和试验。另外，如果它们真的很相似，那么最好去看看其他对性能影响更大的方面。这又是一个艺术影响科学的例子。某些时候，你必须自己决定边界在哪里。

* 通常让Java代码变得更好、更快的方法是写出更好的算法，但这个实现与任何Java调优实践或者Java编码实践无关。

* 这个类可以加入不同实现的历史Bean（立即初始化、延迟初始化等）。它会选择性地缓存从后端数据库（或者模拟的实体管理器）中检索到的数据。这些是处理企业级应用程序性能问题的常见选择（特别是在中间层缓存数据，有时可以给应用程序服务器带来巨大的性能优势）。书中的例子都考虑了这些需要权衡的因素。


### 第3章 Java性能工具箱

* 数以百计的工具可以提供Java应用程序的运行信息，但是研究所有的工具是不切实际的。最重要的工具大都是Java开发工具包（JDK）自带的。尽管还有其他的开源工具和商用工具，但为方便起见，本章主要关注JDK工具。


### 3.1 操作系统工具和分析

* 如果我在Linux桌面系统上运行vmstat 1，会得到如下的几行输出（每秒一行）

* 但是操作系统不会猜测你下一步要做什么，它默认会执行任何可以执行的应用程序，而不是让CPU空闲。

* 如果应用程序优化之后每个请求只需要400毫秒，那么总体的CPU使用率会降低至40%。这是唯一降低CPU使用率有意义的情况——流入系统的负载量固定且应用程序不受限于外部资源。同时，这些优化可以让系统承担更多的负载，最终提高CPU使用率。在微观层面，这种优化仍然只是在短时间（执行请求的400毫秒）内让CPU使用率达到100%——只是CPU峰值的维持时间太短，不足以让大多数工具显示为100%使用率。

* 在这个具体的例子中，应该增加线程池的大小。但是，不要仅仅因为有空闲的CPU可用，就认为应该增加线程池的大小以完成更多的工作。程序无法获得CPU周期，还有我们之前提到过的两个原因——锁或外部资源的瓶颈。在确定行动方案之前，了解程序为什么没有获得CPU很重要。（有关这一主题的更多详细信息，请参见第9章。）


* 如果要运行的线程数量多于可用的CPU，性能就会开始下降。总体来说，为确保性能，你需要让Windows系统的处理器队列长度等于0，或者让Unix系统的运行队列长度小于等于CPU数。这不是一条硬性规定，系统进程和其他进程会定期地暂时提高这个值，这不会对性能产生重大影响。但是如果运行队列在相当长的时间内过长，那就说明机器已经过载，你需要想办法减少机器当前的工作量（通过将任务移至其他机器或者优化代码）。

* 有些系统的基本I/O监视要比其他系统的好。以下是Linux系统上的iostat的部分输出

* 监控磁盘使用率的第二个目的——即使预计应用程序不会进行大量I/O操作——是监控系统是否在进行内存交换。计算机有固定的物理内存，但是它可以用更大的虚拟内存来运行一系列应用程序。应用程序会保留超出其需要的内存量，且通常只在一部分内存上操作。在这两种情况下，操作系统会将没有用到的内存部分保留在磁盘上，只在需要的时候将之转入物理内存。

* 系统工具也可以报告系统是否在交换内存。比如，vmstat的输出中有两列数据（si代表换入，so代表换出），可以警示我们系统是否正在进行内存交换。磁盘活动也说明内存交换可能正在发生。请密切注意这些信息，因为系统在交换内存时——将数据分页从主内存移入磁盘或者进行相反的过程——往往性能相当差。必须配置系统，使其永远不会发生内存交换。

* 幸好，许多开源工具和商用工具可以监控网络带宽。在Unix系统中，受欢迎的命令行工具是nicstat，它可以展示每个网络接口的流量概况，包括接口的使用程度

* 类似typeperf和netstat的工具会报告读写数据的总量，但是要计算网络使用率，你必须在获取带宽后用脚本进行计算。一定要记住，带宽的单位是位/秒（bps），而工具报告的一般是字节/秒（Bps）。1000兆位网络每秒处理125兆字节（125 MB）。在上述例子中，读的速率为225.7KBps，写的速率为176.2KBps，总计3.29Mbps。把它除以接口速率就可以得到约0.33%的使用率。所以nicstat或类似的工具并没有什么神奇之处，它们只是使用起来更方便。


* 网络无法维持100%的使用率。对于本地以太网，使用率持续超过40%就说明接口饱和了。如果是分组交换网络或者利用了不同传输介质的网络，那么最大持续使用率可能会不一样。请咨询网络架构师以确定合适的数值。这个数值和Java无关，Java只不过是利用了操作系统的网络参数和接口。


### 3.2 Java监控工具

* 在JVM所在的机器上，运行所有的这些工具都很容易。如果JVM运行在Docker容器中，非图形化工具（除了jconsole和jvisualvm）可以通过docker exec命令运行，也可以使用nsenter进入Docker容器。不管怎样，这两种情况都假设你在Docker镜像中安装了这些工具，这是值得推荐的做法。Docker镜像通常会被缩减到刚刚好可以运行应用程序的状态，因此可能只包含了JRE，但是在生产环境中，你迟早需要去查看应用程序，所以最好保证Docker镜像中有必要的工具（JDK中自带的）。

* JVM工具可以提供JVM进程的基本运行信息：启动后运行了多久、使用了哪些JVM标志和JVM系统属性等。

* JVM可以设置大量调优标志，其中许多标志是本书的重点。追踪这些标志及其默认值有点令人生畏，上面最后两个jcmd的例子在这方面很有用。command_line命令显示了命令行直接设定的标志，flags命令显示了命令行设置的标志和JVM直接设置的一些标志（因为它们的值可以自动测出来），加上-all命令可以列出所有的标志。

* 这些命令的标志数据会以上述例子中的两种方式显示。第一行输出中的冒号表示标志使用了非默认值。这可能是以下原因导致的：
·标志的值直接通过命令行设定；
·其他标志间接地改变了这个标志的值；
·JVM自动计算出了默认值。

* jinfo本身并没有显示标志是否可操纵（manageable），但是可操纵（正如PrintFlagsFinal输出中所展示的那样）的标志可以通过jinfo打开或者关闭。

* 信息太多？
PrintFlagsFinal命令会输出几百个可用的JVM调优标志（例如JDK 8u202有729个可用的标志）。这些标志中的绝大多数是为了支持工程师从正在运行（运行异常）的应用程序中收集更多的信息。当你知道一个叫作AllocatePrefetchLines的标志（默认值是3）后，你可能很想通过改变这个值让预读指令在特定处理器上运行得更好，但是这种随便的优化并不值得。如果没有令人信服的理由，那么任何一个标志都不应该更改。对AllocatePrefetchLines标志来说，需要了解应用程序的预读性能、运行应用程序的CPU的特点以及改变这个数字会对JVM代码本身有什么影响。

* 请注意，在JDK 8中，jinfo可以更改任一标志的值，但这并不意味着JVM会响应这个更改。比如，大多数影响GC算法行为的标志会在启动时决定垃圾回收器的行为方式，之后通过jinfo更改这些标志并不会改变JVM的行为，JVM会根据初始的算法继续执行。所以这个方法只对PrintFlagsFinal命令的输出结果中标记为manageable的标志起作用。在JDK 11中，jinfo会在你尝试修改不可变标志的值时报告错误。

* jconsole和jvisualvm都可以实时显示应用程序中正在运行的线程的数量。查看运行的线程栈很重要，可以用于判断线程是否阻塞。


### 3.3 性能分析工具

* 性能分析器是性能分析师工具箱中最重要的工具。Java有很多性能分析器，每个都各有优缺点。性能分析常常需要使用各种工具——特别是采样分析器。采样分析器往往会以不同的方式展示问题。因此，有的分析器在某些应用程序上能很好地确定性能问题，而在其他应用程序上就不能。

* 这是最常见的采样误差，但绝不是唯一的一个。想要减小误差，就要延长采样周期并减小采样间隔。减小采样间隔和“最小化性能分析的影响”这个目标相反，我们需要在这二者之间寻找一个平衡点。不同的性能分析工具处理这个平衡点的方式不同，这就是各种工具报告的数据有很大不同的原因之一。

